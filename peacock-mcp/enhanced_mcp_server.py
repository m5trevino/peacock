# Enhanced MCP Server with Peacock 4-Stage Integration
import http.server
import socketserver
import json
import os
import urllib.request
import subprocess
import tempfile
import datetime

# --- CONFIGURATION ---
HOST = "127.0.0.1"
PORT = 8000
PROCESS_PATH = "/process"

# --- LOCAL LLM CONFIGURATION (OLLAMA) ---
LOCAL_LLM_URL = "http://127.0.0.1:11434/api/generate"
LOCAL_LLM_MODEL_NAME = "codegeex4:9b-all-q4_K_M"

# --- PEACOCK STAGE HANDLERS ---

class SparkHandler:
    """Requirements Analysis Stage"""
    
    def analyze_requirements(self, data):
        prompt = self._build_spark_prompt(data['text'])
        llm_response = call_llm(prompt)
        
        if llm_response.get("success"):
            return self._parse_spark_response(llm_response['text'])
        return {"error": "Spark analysis failed"}
    
    def _build_spark_prompt(self, project_idea):
        return f"""
Act as Spark, a strategic requirements analyst. Analyze this project idea and provide:

Project: {project_idea}

Provide analysis in this EXACT format:

**1. Core Objective:**
[One clear sentence describing the main goal]

**2. Current State:**
[Current situation/problems this solves]

**3. Target State:**
[Desired end state after implementation]

**4. In Scope:**
- [Feature 1]
- [Feature 2]
- [Feature 3]

**5. Out of Scope:**
- [What's NOT included]
- [Future considerations]

Keep it strategic and concise.
"""
    
    def _parse_spark_response(self, llm_text):
        return {
            "stage": "spark",
            "analysis_type": "requirements",
            "result_text": llm_text,
            "report_html": self._generate_spark_html(llm_text)
        }
    
    def _generate_spark_html(self, content):
        html_content = f"""
<!DOCTYPE html>
<html>
<head>
    <title>Peacock Spark - Requirements Analysis</title>
    <style>
        body {{ font-family: 'SF Pro Display', -apple-system, sans-serif; 
               max-width: 1200px; margin: 0 auto; padding: 40px 20px; 
               background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
               color: #333; }}
        .container {{ background: white; border-radius: 20px; 
                     padding: 40px; box-shadow: 0 20px 60px rgba(0,0,0,0.1); }}
        h1 {{ color: #2d3748; border-bottom: 3px solid #667eea; padding-bottom: 15px; }}
        .stage-badge {{ background: #667eea; color: white; padding: 8px 16px; 
                       border-radius: 20px; font-weight: bold; display: inline-block; 
                       margin-bottom: 20px; }}
        pre {{ background: #f7fafc; padding: 20px; border-radius: 10px; 
               border-left: 4px solid #667eea; overflow-x: auto; }}
    </style>
</head>
<body>
    <div class="container">
        <div class="stage-badge">ðŸ¦š STAGE 1: SPARK</div>
        <h1>Requirements Analysis</h1>
        <pre>{content}</pre>
        <p><em>Generated by Peacock Spark at {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</em></p>
    </div>
</body>
</html>
"""
        return self._save_html_report("spark", html_content)


class FalconHandler:
    """Architecture Design Stage"""
    
    def design_architecture(self, data):
        prompt = self._build_falcon_prompt(data['text'])
        llm_response = call_llm(prompt)
        
        if llm_response.get("success"):
            return self._parse_falcon_response(llm_response['text'])
        return {"error": "Falcon architecture design failed"}
    
    def _build_falcon_prompt(self, project_requirements):
        return f"""
Act as Falcon, a solution architect. Design the technical architecture for this project:

Requirements: {project_requirements}

Provide architecture in this EXACT format:

**1. Technology Stack:**
- Frontend: [Specific framework/library]
- Backend: [Specific framework/language]
- Database: [Specific database choice]
- APIs: [External services]
- Deployment: [Cloud/hosting strategy]

**2. Architecture Pattern:**
[Describe the overall pattern - monolithic, microservices, etc.]

**3. File Structure:**
```
project-name/
â”œâ”€â”€ frontend/
â”œâ”€â”€ backend/
â”œâ”€â”€ database/
â””â”€â”€ docs/
```

**4. Data Flow:**
[Describe how data moves through the system]

**5. Key Implementation Decisions:**
- [Decision 1 with rationale]
- [Decision 2 with rationale]

Be specific with technologies and justify choices.
"""
    
    def _parse_falcon_response(self, llm_text):
        return {
            "stage": "falcon",
            "analysis_type": "architecture",
            "result_text": llm_text,
            "report_html": self._generate_falcon_html(llm_text)
        }
    
    def _generate_falcon_html(self, content):
        html_content = f"""
<!DOCTYPE html>
<html>
<head>
    <title>Peacock Falcon - Architecture Design</title>
    <style>
        body {{ font-family: 'SF Pro Display', -apple-system, sans-serif; 
               max-width: 1200px; margin: 0 auto; padding: 40px 20px; 
               background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
               color: #333; }}
        .container {{ background: white; border-radius: 20px; 
                     padding: 40px; box-shadow: 0 20px 60px rgba(0,0,0,0.1); }}
        h1 {{ color: #2d3748; border-bottom: 3px solid #f093fb; padding-bottom: 15px; }}
        .stage-badge {{ background: #f093fb; color: white; padding: 8px 16px; 
                       border-radius: 20px; font-weight: bold; display: inline-block; 
                       margin-bottom: 20px; }}
        pre {{ background: #f7fafc; padding: 20px; border-radius: 10px; 
               border-left: 4px solid #f093fb; overflow-x: auto; }}
    </style>
</head>
<body>
    <div class="container">
        <div class="stage-badge">ðŸ¦… STAGE 2: FALCON</div>
        <h1>Architecture Design</h1>
        <pre>{content}</pre>
        <p><em>Generated by Peacock Falcon at {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</em></p>
    </div>
</body>
</html>
"""
        return self._save_html_report("falcon", html_content)


class EagleHandler:
    """Implementation Stage"""
    
    def generate_implementation(self, data):
        prompt = self._build_eagle_prompt(data['text'])
        llm_response = call_llm(prompt)
        
        if llm_response.get("success"):
            return self._parse_eagle_response(llm_response['text'])
        return {"error": "Eagle implementation failed"}
    
    def _build_eagle_prompt(self, architecture_design):
        return f"""
Act as Eagle, an implementation specialist. Create executable setup and code for this architecture:

Architecture: {architecture_design}

Provide implementation in this EXACT format:

**1. Setup Commands:**
```bash
# Complete setup commands here
npm init -y
npm install express react
# etc...
```

**2. Directory Structure:**
```
project/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â””â”€â”€ utils/
â”œâ”€â”€ public/
â””â”€â”€ package.json
```

**3. Key Files to Create:**
**server.js:**
```javascript
// Complete working server code
```

**App.js:**
```javascript
// Complete working frontend code
```

**4. Initial Code Scaffolding:**
[Provide minimal working code for each component]

**5. First Working Prototype Steps:**
1. Run setup commands
2. Start development server
3. Test basic functionality
4. Verify all components work

Make it executable and ready to run immediately.
"""
    
    def _parse_eagle_response(self, llm_text):
        return {
            "stage": "eagle",
            "analysis_type": "implementation",
            "result_text": llm_text,
            "report_html": self._generate_eagle_html(llm_text)
        }
    
    def _generate_eagle_html(self, content):
        html_content = f"""
<!DOCTYPE html>
<html>
<head>
    <title>Peacock Eagle - Implementation Guide</title>
    <style>
        body {{ font-family: 'SF Pro Display', -apple-system, sans-serif; 
               max-width: 1200px; margin: 0 auto; padding: 40px 20px; 
               background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
               color: #333; }}
        .container {{ background: white; border-radius: 20px; 
                     padding: 40px; box-shadow: 0 20px 60px rgba(0,0,0,0.1); }}
        h1 {{ color: #2d3748; border-bottom: 3px solid #4facfe; padding-bottom: 15px; }}
        .stage-badge {{ background: #4facfe; color: white; padding: 8px 16px; 
                       border-radius: 20px; font-weight: bold; display: inline-block; 
                       margin-bottom: 20px; }}
        pre {{ background: #f7fafc; padding: 20px; border-radius: 10px; 
               border-left: 4px solid #4facfe; overflow-x: auto; }}
        code {{ background: #e2e8f0; padding: 2px 6px; border-radius: 4px; }}
    </style>
</head>
<body>
    <div class="container">
        <div class="stage-badge">ðŸ¦… STAGE 3: EAGLE</div>
        <h1>Implementation Guide</h1>
        <pre>{content}</pre>
        <p><em>Generated by Peacock Eagle at {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</em></p>
    </div>
</body>
</html>
"""
        return self._save_html_report("eagle", html_content)


class HawkHandler:
    """Quality Assurance Stage"""
    
    def analyze_quality(self, data):
        prompt = self._build_hawk_prompt(data['text'])
        llm_response = call_llm(prompt)
        
        if llm_response.get("success"):
            return self._parse_hawk_response(llm_response['text'])
        return {"error": "Hawk QA analysis failed"}
    
    def _build_hawk_prompt(self, implementation_details):
        return f"""
Act as Hawk, a quality assurance specialist. Create comprehensive QA strategy for this implementation:

Implementation: {implementation_details}

Provide QA strategy in this EXACT format:

**1. Test Cases:**
- Functional tests for core features
- Edge cases and error scenarios
- Integration test requirements

**2. Security Validation:**
- Authentication/authorization checks
- Input validation requirements
- Data protection measures

**3. Performance Considerations:**
- Load testing requirements
- Scalability checkpoints
- Resource optimization

**4. Error Handling Scenarios:**
- Network failure handling
- Data corruption recovery
- User error management

**5. Production Readiness Checklist:**
- Deployment requirements
- Monitoring setup
- Backup strategies
- Compliance checks

Be specific and actionable for each area.
"""
    
    def _parse_hawk_response(self, llm_text):
        return {
            "stage": "hawk", 
            "analysis_type": "quality_assurance",
            "result_text": llm_text,
            "report_html": self._generate_hawk_html(llm_text)
        }
    
    def _generate_hawk_html(self, content):
        html_content = f"""
<!DOCTYPE html>
<html>
<head>
    <title>Peacock Hawk - Quality Assurance</title>
    <style>
        body {{ font-family: 'SF Pro Display', -apple-system, sans-serif; 
               max-width: 1200px; margin: 0 auto; padding: 40px 20px; 
               background: linear-gradient(135deg, #fa709a 0%, #fee140 100%);
               color: #333; }}
        .container {{ background: white; border-radius: 20px; 
                     padding: 40px; box-shadow: 0 20px 60px rgba(0,0,0,0.1); }}
        h1 {{ color: #2d3748; border-bottom: 3px solid #fa709a; padding-bottom: 15px; }}
        .stage-badge {{ background: #fa709a; color: white; padding: 8px 16px; 
                       border-radius: 20px; font-weight: bold; display: inline-block; 
                       margin-bottom: 20px; }}
        pre {{ background: #f7fafc; padding: 20px; border-radius: 10px; 
               border-left: 4px solid #fa709a; overflow-x: auto; }}
        .checklist {{ background: #f0fff4; padding: 15px; border-radius: 8px; 
                     border-left: 4px solid #38a169; }}
    </style>
</head>
<body>
    <div class="container">
        <div class="stage-badge">ðŸ¦… STAGE 4: HAWK</div>
        <h1>Quality Assurance Strategy</h1>
        <pre>{content}</pre>
        <p><em>Generated by Peacock Hawk at {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</em></p>
    </div>
</body>
</html>
"""
        return self._save_html_report("hawk", html_content)


# Shared HTML report saving method
def _save_html_report(stage_name, html_content):
    """Save HTML report and return filepath"""
    reports_dir = os.path.expanduser("~/peacock_reports")
    os.makedirs(reports_dir, exist_ok=True)
    
    timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
    filename = f"peacock_{stage_name}_{timestamp}.html"
    filepath = os.path.join(reports_dir, filename)
    
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(html_content)
    
    return filepath


# Initialize stage handlers
spark_handler = SparkHandler()
falcon_handler = FalconHandler()
eagle_handler = EagleHandler()
hawk_handler = HawkHandler()


# --- ENHANCED LLM FUNCTIONS ---

def build_llm_prompt(command, text, language):
    """Builds prompts for both traditional and Peacock stage commands"""
    
    # Peacock stage commands
    if command == "spark_analysis":
        return spark_handler._build_spark_prompt(text)
    elif command == "falcon_architecture":
        return falcon_handler._build_falcon_prompt(text)
    elif command == "eagle_implementation":
        return eagle_handler._build_eagle_prompt(text)
    elif command == "hawk_qa":
        return hawk_handler._build_hawk_prompt(text)
    elif command == "peacock_full":
        return f"""
Analyze this project idea through all 4 Peacock stages:

Project: {text}

Provide complete analysis covering:
1. Requirements (Spark)
2. Architecture (Falcon)  
3. Implementation (Eagle)
4. Quality Assurance (Hawk)

Format each stage clearly with headers.
"""
    
    # Traditional code analysis commands
    elif command == "explain":
        return f"Explain the following {language} code:\n\n{text}\n\nProvide a clear, concise explanation."
    elif command == "fix":
        return f"Review and fix this {language} code. Provide corrected version and explanation:\n\n{text}"
    elif command == "rewrite":
        return f"Rewrite this {language} code to be more efficient/idiomatic:\n\n{text}"
    elif command == "alternatives":
        return f"Suggest alternative approaches for this {language} code:\n\n{text}"
    elif command == "question":
        return f"Analyze this {language} code and provide insights:\n\n{text}"
    else:
        return f"Analyze the following {language} code:\n\n{text}"


def call_llm(prompt):
    """Calls the local Ollama API server with the given prompt"""
    try:
        llm_request_payload = {
            "model": LOCAL_LLM_MODEL_NAME,
            "prompt": prompt,
            "stream": False
        }
        
        json_data = json.dumps(llm_request_payload).encode('utf-8')
        req = urllib.request.Request(LOCAL_LLM_URL, data=json_data,
                                   headers={'Content-Type': 'application/json'},
                                   method='POST')

        print(f"MCP: Calling local LLM ({LOCAL_LLM_MODEL_NAME})...")

        with urllib.request.urlopen(req) as response:
            llm_response_json_raw = response.read().decode('utf-8')
            llm_response_json = json.loads(llm_response_json_raw)
            llm_text_response = llm_response_json.get('response', '')

            print("MCP: Received response from local LLM.")
            return {"success": True, "text": llm_text_response}

    except Exception as e:
        print(f"MCP ERROR: LLM call failed: {e}")
        return {"error": f"LLM call failed: {e}"}


def process_llm_response(command, llm_raw_text, location_info):
    """Enhanced IRP with Peacock stage routing"""
    
    # Route Peacock stage commands to appropriate handlers
    if command == "spark_analysis":
        return spark_handler._parse_spark_response(llm_raw_text)
    elif command == "falcon_architecture":
        return falcon_handler._parse_falcon_response(llm_raw_text)
    elif command == "eagle_implementation":
        return eagle_handler._parse_eagle_response(llm_raw_text)
    elif command == "hawk_qa":
        return hawk_handler._parse_hawk_response(llm_raw_text)
    elif command == "peacock_full":
        # Full analysis - create comprehensive report
        html_content = f"""
<!DOCTYPE html>
<html>
<head>
    <title>Peacock Complete Analysis</title>
    <style>
        body {{ font-family: 'SF Pro Display', -apple-system, sans-serif; 
               max-width: 1200px; margin: 0 auto; padding: 40px 20px; 
               background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
               color: #333; }}
        .container {{ background: white; border-radius: 20px; 
                     padding: 40px; box-shadow: 0 20px 60px rgba(0,0,0,0.1); }}
        h1 {{ color: #2d3748; border-bottom: 3px solid #667eea; padding-bottom: 15px; }}
        .full-badge {{ background: linear-gradient(135deg, #667eea, #764ba2); 
                      color: white; padding: 12px 24px; border-radius: 25px; 
                      font-weight: bold; display: inline-block; margin-bottom: 30px;
                      font-size: 18px; }}
        pre {{ background: #f7fafc; padding: 20px; border-radius: 10px; 
               border-left: 4px solid #667eea; overflow-x: auto; }}
    </style>
</head>
<body>
    <div class="container">
        <div class="full-badge">ðŸ¦š PEACOCK COMPLETE ANALYSIS</div>
        <h1>Full Project Analysis</h1>
        <pre>{llm_raw_text}</pre>
        <p><em>Generated by Peacock Complete at {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</em></p>
    </div>
</body>
</html>
"""
        return {
            "analysis_type": "complete",
            "result_text": llm_raw_text,
            "report_html": _save_html_report("complete", html_content)
        }
    
    # Traditional code commands (existing logic)
    internal_data = {}
    
    if command in ["explain", "question"]:
        internal_data["explanation_text"] = llm_raw_text
        internal_data["result_text"] = llm_raw_text
    elif command in ["fix", "rewrite"]:
        # Parse code fixes
        suggested_change = {
            "type": "replace",
            "replacement_code": "Could not parse suggested code from LLM.",
            "explanation": "Could not parse explanation from LLM.",
            "start_line_1based": location_info.get('selected_region', {}).get('start', {}).get('line_1based', '??'),
            "end_line_1based": location_info.get('selected_region', {}).get('end', {}).get('line_1based', '??')
        }
        
        # Simple code block extraction
        lines = llm_raw_text.splitlines()
        code_blocks = []
        in_code_block = False
        current_code_block = []
        
        for line in lines:
            if line.strip().startswith("```"):
                if in_code_block:
                    code_blocks.append("\n".join(current_code_block))
                    current_code_block = []
                    in_code_block = False
                else:
                    in_code_block = True
            elif in_code_block:
                current_code_block.append(line)
        
        if code_blocks:
            suggested_change["replacement_code"] = code_blocks[-1].strip()
        
        internal_data["suggested_change"] = suggested_change
    else:
        internal_data["result_text"] = llm_raw_text
    
    internal_data["_raw_llm_response"] = llm_raw_text
    return internal_data


# --- ENHANCED REQUEST HANDLER ---

class EnhancedMCPRequestHandler(http.server.BaseHTTPRequestHandler):
    def log_request(self, code='-', size='-'):
        pass

    def do_POST(self):
        if self.path == PROCESS_PATH:
            content_length = int(self.headers['Content-Length'])
            post_data = self.rfile.read(content_length)

            try:
                received_data = json.loads(post_data.decode('utf-8'))
                
                command = received_data.get('command', 'unknown')
                text_to_process = received_data.get('text', '')
                language = received_data.get('language', 'unknown')
                location_info = received_data.get('location', {})

                print("Enhanced MCP: Received data from EIP:")
                print("---")
                print("Command: {}".format(command))
                print("Language: {}".format(language))
                print("File: {}".format(os.path.basename(location_info.get('filepath', 'N/A'))))
                print("---")

                # Build prompt and call LLM
                llm_prompt = build_llm_prompt(command, text_to_process, language)
                llm_response = call_llm(llm_prompt)

                if llm_response.get("success"):
                    llm_raw_text = llm_response.get("text", "")
                    internal_structured_data = process_llm_response(command, llm_raw_text, location_info)

                    # Prepare response
                    response_payload = {
                        "status": "success",
                        "command": command,
                        "message": "Enhanced MCP processed successfully.",
                        "internal_data": internal_structured_data,
                        "location": location_info
                    }
                    
                    # Add report filepath if generated
                    if "report_html" in internal_structured_data:
                        response_payload["report_filepath"] = internal_structured_data["report_html"]

                    self.send_response(200)
                    self.send_header('Content-type', 'application/json')
                    self.end_headers()
                    self.wfile.write(json.dumps(response_payload).encode('utf-8'))

                else:
                    error_message = llm_response.get("error", "Unknown LLM error.")
                    self.send_response(500)
                    self.send_header('Content-type', 'application/json')
                    self.end_headers()
                    error_payload = {
                        "status": "error",
                        "command": command,
                        "message": f"Enhanced MCP: LLM processing failed: {error_message}",
                        "internal_data": {"_llm_error": error_message}
                    }
                    self.wfile.write(json.dumps(error_payload).encode('utf-8'))

            except Exception as e:
                self.send_response(500)
                self.send_header('Content-type', 'application/json')
                self.end_headers()
                error_payload = {
                    "status": "error",
                    "message": "Enhanced MCP: Processing error: {}".format(e),
                    "command": "internal_error"
                }
                self.wfile.write(json.dumps(error_payload).encode('utf-8'))
                print("Enhanced MCP ERROR: {}".format(e))
        else:
            self.send_response(404)
            self.end_headers()
            self.wfile.write(b'404 Not Found')


# --- SERVER STARTUP ---
if __name__ == "__main__":
    with socketserver.TCPServer((HOST, PORT), EnhancedMCPRequestHandler, bind_and_activate=False) as httpd:
        httpd.allow_reuse_address = True
        httpd.server_bind()
        httpd.server_activate()

        print("Enhanced MCP: Starting Peacock server on {}:{}".format(HOST, PORT))
        print("Enhanced MCP: Peacock stages ready - Spark/Falcon/Eagle/Hawk")
        print("Enhanced MCP: Press Ctrl+C to stop.")

        try:
            httpd.serve_forever()
        except KeyboardInterrupt:
            print("\nEnhanced MCP: Stopping Peacock server.")
            httpd.shutdown()
            print("Enhanced MCP: Peacock server stopped.")